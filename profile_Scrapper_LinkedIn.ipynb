{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "31109552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter the exact LinkedIn username you use to login (email/phone?):\n",
      "\n",
      "Please enter the exact LinkedIn password:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests, time, random\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from datetime import datetime\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException, TimeoutException\n",
    "#\n",
    "# Get linkedin username and password form user:\n",
    "print(\"Please enter the exact LinkedIn username you use to login (email/phone?):\")\n",
    "username_string = str(input())\n",
    "print()\n",
    "print(\"Please enter the exact LinkedIn password:\")\n",
    "password_string = str(input())\n",
    "print()\n",
    "# print(\"Please enter your usernmae exactly how it appears in your profile link (after '/in') :\")\n",
    "# link_username = str(input())\n",
    "# print()\n",
    "\n",
    "#create a browser-specific (Google Chrome) web navigation simulator:\n",
    "service = Service()\n",
    "options = webdriver.ChromeOptions()\n",
    "browser = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "# Navigate to the LinkedIn login page\n",
    "browser.get(\"https://www.linkedin.com/login\")\n",
    "\n",
    "# Enter your login credentials\n",
    "elementID = browser.find_element(By.ID,'username')\n",
    "elementID.send_keys(username_string)\n",
    "elementID = browser.find_element(By.ID,'password')\n",
    "elementID.send_keys(password_string)\n",
    "elementID.submit()\n",
    "time.sleep(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f30aae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Name=[]\n",
    "Age=[]\n",
    "Title=[]\n",
    "Followers=[]\n",
    "# Connections=[]\n",
    "#engagement=[]\n",
    "#eng_3_post=[]\n",
    "#posts_in_weeks=[]\n",
    "#last_post=[]\n",
    "Exp=[]\n",
    "Des=[]\n",
    "Loca=[]\n",
    "Com_Name=[]\n",
    "Edu=[]\n",
    "# Certification=[]\n",
    "Re_Skl=[]\n",
    "time_post=['1m', '2m', '3m', '4m', '5m', '6m', '7m', '8m', '9m', '10m', '11m', '12m', '13m', '14m', '15m', '16m', '17m', '18m', '19m', '20m', '21m', '22m', '23m', '24m', '25m', '26m', '27m', '28m', '29m', '30m', '31m', '32m', '33m', '34m', '35m', '36m', '37m', '38m', '39m', '40m', '41m', '42m', '43m', '44m', '45m', '46m', '47m', '48m', '49m', '50m', '51m', '52m', '53m', '54m', '55m', '56m', '57m', '58m', '59m',\n",
    "      '1h', '2h', '3h', '4h', '5h', '6h', '7h', '8h', '9h', '10h', '11h', '12h', '13h', '14h', '15h', '16h', '17h', '18h', '19h', '20h', '21h', '22h', '23h', '24h',\n",
    "      '1d','2d','3d','4d','5d','6d',\n",
    "      '1w'\n",
    "     ]\n",
    "c=0\n",
    "\n",
    "links = [\n",
    "#Place the LinkedIn URLs here.\n",
    "# \"https://www.linkedin.com/in/\"\n",
    "\n",
    "]\n",
    "\n",
    "\n",
    "# Define a function to add a random delay\n",
    "def random_sleep(min_delay=3, max_delay=7):\n",
    "    delay = random.uniform(min_delay, max_delay)\n",
    "    time.sleep(delay)\n",
    "\n",
    "for i in links:\n",
    "    c=c+1\n",
    "    #Open Link\n",
    "    browser.get(i)\n",
    "    random_sleep()  \n",
    "    \n",
    "    try:\n",
    "        # Scrolling to get full page loaded\n",
    "        SCROLL_PAUSE_TIME = 5\n",
    "        # Get scroll height\n",
    "        last_height = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "        for i in range(3):\n",
    "            # Scroll down to bottom\n",
    "            browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "            # Wait to load page\n",
    "            # Wait to load page\n",
    "            random_sleep()  # Add a random sleep here\n",
    "    #         time.sleep(SCROLL_PAUSE_TIME)\n",
    "\n",
    "            # Calculate new scroll height and compare with last scroll height\n",
    "            new_height = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "            if new_height == last_height:\n",
    "                break\n",
    "            last_height = new_height\n",
    "            \n",
    "    except AttributeError:\n",
    "        continue\n",
    "    \n",
    "    browser.execute_script(\"window.scrollBy(0,-20000);\")\n",
    "    random_sleep()  # Add a random sleep here\n",
    "    #Getting HTMML tags\n",
    "    src = browser.page_source\n",
    "    soup = BeautifulSoup(src, 'lxml')\n",
    "    experience = soup.find_all(\"section\", {\"class\": \"artdeco-card ember-view relative break-words pb3 mt2\"})\n",
    "\n",
    "    #Scrapping name\n",
    "    name=browser.find_element(By.TAG_NAME,'h1').text.strip('\\n...')\n",
    "    name\n",
    "    random_sleep()\n",
    "    \n",
    "    #Scrapping bio\n",
    "    try:\n",
    "        title = soup.find(\"div\", {'class': 'text-body-medium break-words'})\n",
    "        bio = title.get_text().strip()\n",
    "    except:\n",
    "        bio='None'\n",
    "    #Scrapping work loaction\n",
    "    try:\n",
    "        work_location=soup.find(\"div\", {'class': 'pv-text-details__left-panel mt2'})\n",
    "        work_loc=work_location.find('span').get_text().strip()\n",
    "    except:\n",
    "        work_loc='None'\n",
    "    random_sleep()\n",
    "    \n",
    "     # Scrapping current/last designation\n",
    "    try:\n",
    "        experience = soup.find_all(\"section\", {\"class\": \"artdeco-card ember-view relative break-words pb3 mt2\"})\n",
    "        for i in range(len(experience)):\n",
    "            tag_exp=experience[i].find('span').get_text().strip()\n",
    "            if tag_exp=='Experience':\n",
    "                break\n",
    "            else:\n",
    "                continue\n",
    "        expp=experience[i].find(\"div\",{\"class\":\"display-flex flex-column full-width align-self-center\"})\n",
    "        li_tag=experience[i].find_all(\"li\",{\"class\":\"pvs-list__item--one-column\"})\n",
    "        div_tag = li_tag[1].find('div',{'class':'display-flex align-items-center mr1 hoverable-link-text t-bold'})\n",
    "        spans_tag = div_tag.find('span')\n",
    "        designation=spans_tag.get_text().strip()\n",
    "    except:\n",
    "        spanns_tag=expp.find('span')\n",
    "        designation=spanns_tag.get_text().strip()\n",
    "       \n",
    "    random_sleep()\n",
    "        \n",
    "    # Initialize followers and connections with default values\n",
    "    no_of_fol = '0'\n",
    "    no_of_con = '0'\n",
    "    #Followers\n",
    "    try:\n",
    "        followers = soup.find(\"li\", {'class': 'text-body-small t-black--light inline-block'})\n",
    "        followers=followers.find('span')\n",
    "        no_of_fol = followers.get_text().strip()\n",
    "    except AttributeError:\n",
    "        for i in range(len(experience)):\n",
    "            tag_exp=experience[i].find('span').get_text().strip()\n",
    "            if tag_exp=='Activity':\n",
    "                break\n",
    "            else:\n",
    "                continue\n",
    "        followers=experience[i].find('p')\n",
    "        followers=followers.find('span',{'aria-hidden':'true'})\n",
    "        no_of_fol = followers.get_text().strip().replace(' followers', '')\n",
    "    except IndexError:\n",
    "        no_of_fol='None'\n",
    "\n",
    "    random_sleep()\n",
    "    #Connection\n",
    "#     no_of_con = '0' \n",
    "#     try:\n",
    "#         conn_elements = soup.find_all(\"li\", {'class': 'text-body-small'})\n",
    "#         if len(conn_elements) >= 1:  # Check if the connection tag is present\n",
    "#             conn = conn_elements[0]\n",
    "#             no_of_con = conn.get_text().strip().replace(' connections', '')\n",
    "#             if no_of_con == '500+':\n",
    "#                 no_of_con = '500+'\n",
    "#     except AttributeError:\n",
    "#         pass  # This will handle the case where the tag is not found, but no action is taken\n",
    "#     except Exception as e:\n",
    "#         print(f\"An error occurred: {e}\")  # Print the error message for debugging\n",
    "  \n",
    "    #Scrapping company name\n",
    "    try:\n",
    "        try:\n",
    "            li_tag=experience[i].find_all('li')\n",
    "            div_tag = li_tag[0].find('div',{'class':'display-flex align-items-center mr1 hoverable-link-text t-bold'})\n",
    "            span_tag = div_tag.find('span')\n",
    "            company_name=span_tag.get_text().strip()\n",
    "        except:\n",
    "            spann_tag = expp.find('span',{'class':'t-14 t-normal'})\n",
    "            company_name=spann_tag.get_text().split(' Â· ')[0].strip()\n",
    "    except:\n",
    "        company_name='None'\n",
    "        \n",
    "    random_sleep()\n",
    "    #else:\n",
    "    #    company_name=None\n",
    "\n",
    "    # Recent Education\n",
    "    try:\n",
    "        for i in range(len(experience)):\n",
    "            tag_edu=experience[i].find('span').get_text().strip()\n",
    "            if tag_edu=='Education':\n",
    "                break\n",
    "            else:\n",
    "                continue\n",
    "        re_ed=experience[i].find('ul')\n",
    "        recent_edu=re_ed.find('span',{'class':'t-14 t-normal'})\n",
    "        recent_edu=recent_edu.find('span').get_text().strip()\n",
    "    except:\n",
    "        recent_edu='None'\n",
    "    random_sleep()\n",
    "    \n",
    "    # Years of experience\n",
    "    try:\n",
    "        ex_exp=re_ed.find('span',{'class':'t-14 t-normal t-black--light'})\n",
    "        ex_exp=ex_exp.find('span')\n",
    "        exp=ex_exp.get_text().strip()\n",
    "        exp=exp[-4:]\n",
    "        exp=int(exp)\n",
    "        current_datetime = datetime.now()\n",
    "        current_year = current_datetime.year\n",
    "        years_of_exp=current_year-exp\n",
    "        if years_of_exp>=0:\n",
    "            yr_exp=years_of_exp\n",
    "        else:\n",
    "            yr_exp=0\n",
    "    except:\n",
    "        yr_exp='None'\n",
    "\n",
    "    #Age\n",
    "    try:\n",
    "        if(yr_exp>=0 and yr_exp<5):\n",
    "            age='20-25'\n",
    "        elif(yr_exp>=5 and yr_exp<10):\n",
    "            age='25-30'\n",
    "        elif(yr_exp>=10 and yr_exp<15):\n",
    "            age='30-35'\n",
    "        elif(yr_exp>=15 and yr_exp<20):\n",
    "            age='35-40'\n",
    "        elif(yr_exp>=20 and yr_exp<25):\n",
    "            age='40-45'\n",
    "        elif(yr_exp>=25 and yr_exp<30):\n",
    "            age='45-50'\n",
    "        elif(yr_exp>=30 and yr_exp<35):\n",
    "            age='50-55'\n",
    "        elif(yr_exp>=35 and yr_exp<40):\n",
    "            age='55-60'\n",
    "    except:\n",
    "        age='None'\n",
    "\n",
    "    # Skills\n",
    "    try:\n",
    "        for i in range(len(experience)):\n",
    "            tag_skill=experience[i].find('span').get_text().strip()\n",
    "            if tag_skill=='Skills':\n",
    "                break\n",
    "            else:\n",
    "                continue\n",
    "        skill_sec=experience[i].find('ul')\n",
    "        skills_sec=skill_sec.find_all('li',{\"class\":'artdeco-list__item pvs-list__item--line-separated pvs-list__item--one-column pvs-list--ignore-first-item-top-padding'})#new\n",
    "        related_skills=[]\n",
    "        for i in range(len(skills_sec)):\n",
    "            skills=skills_sec[i].find('span').get_text().strip()\n",
    "            related_skills.append(skills)\n",
    "    except:\n",
    "        related_skills='None'\n",
    "    random_sleep()\n",
    "        \n",
    "    #Certificates and Licenses\n",
    "#     certi_name=None#new\n",
    "#     try:\n",
    "#         try:\n",
    "#             certi_load_button=browser.find_elements(By.XPATH,'//div[contains(@class,\"pvs-list__footer-wrapper\")]')\n",
    "#             for i in certi_load_button:\n",
    "#                 spell=i.text.strip()\n",
    "#                 if spell[-25:]=='licenses & certifications':\n",
    "#                     i.click()\n",
    "#                     break\n",
    "#             if spell[-25:]=='licenses & certifications':\n",
    "#                 # Scrolling to get full page loaded\n",
    "#                 SCROLL_PAUSE_TIME = 5\n",
    "#                 # Get scroll height\n",
    "#                 last_height = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "#                 for i in range(3):\n",
    "#                     # Scroll down to bottom\n",
    "#                     browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "#                     # Wait to load page\n",
    "#                     time.sleep(SCROLL_PAUSE_TIME)\n",
    "\n",
    "#                     # Calculate new scroll height and compare with last scroll height\n",
    "#                     new_height = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "#                     if new_height == last_height:\n",
    "#                         break\n",
    "#                     last_height = new_height\n",
    "#                 browser.execute_script(\"window.scrollBy(0,-400000);\")\n",
    "#                 certifications=browser.find_elements(By.XPATH,'//div[contains(@class,\"display-flex flex-wrap align-items-center full-height\")]')\n",
    "#                 certi_name=[]\n",
    "#                 for certificate in certifications:\n",
    "#                     certi=certificate.find_element(By.CSS_SELECTOR,'div>div>div>span').text.strip()\n",
    "#                     certi_name.append(certi)\n",
    "#         except:\n",
    "#             for i in range(len(experience)):\n",
    "#                 tag_skill=experience[i].find('span').get_text().strip()\n",
    "#                 if tag_skill=='Licenses & certifications':\n",
    "#                     break\n",
    "#                 else:\n",
    "#                     continue\n",
    "#             lic_sec=experience[i].find_all('li',{'class':'artdeco-list__item pvs-list__item--line-separated pvs-list__item--one-column'})\n",
    "#             certi_name=[]\n",
    "#             for i in range(len(lic_sec)):\n",
    "#                 certi=lic_sec[i].find('span',{'aria-hidden':'true'}).get_text().strip()\n",
    "#                 certi_name.append(certi)\n",
    "#     except:\n",
    "#         if certi_name is None:#new\n",
    "#             certi_name=['None']\n",
    "\n",
    "  \n",
    "    #appending for making dataset\n",
    "    Name.append(name)\n",
    "    Age.append(age)\n",
    "    Exp.append(yr_exp)\n",
    "    Title.append(bio)\n",
    "    Followers.append(no_of_fol)\n",
    "#     Connections.append(no_of_con)\n",
    "    #engagement.append(average)\n",
    "    #eng_3_post.append(react_total)\n",
    "    #posts_in_weeks.append(count)\n",
    "    #last_post.append(post_date[0])\n",
    "    Des.append(designation)\n",
    "    Loca.append(work_loc)\n",
    "    Com_Name.append(company_name)\n",
    "    Edu.append(recent_edu)\n",
    "    Re_Skl.append([related_skills])\n",
    "#     Certification.append([certi_name])\n",
    "\n",
    "    random_number = random.randint(1, 10)\n",
    "    random_sleep()  # Add a random sleep here\n",
    "    time.sleep(30)\n",
    "    print(f'Link {c} is completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b2ac9c05",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data={'Name':Name,'Title':Title,'Followers':Followers,'Age(approx)':Age,'Current/ Last designation':Des,'Years in Experience(approx)':Exp,'Current Workplace location':Loca,'Current/Last Company Name':Com_Name,' Recent Education':Edu,'Related Skills':Re_Skl}\n",
    "df=pd.DataFrame(data)\n",
    "df.to_excel(\"aaina_liker_profile_2.xlsx\",index=False)\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3478b60a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
